{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from typing import Optional, Tuple\n",
    "\n",
    "import gym\n",
    "import imageio\n",
    "import numpy as np\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, VecFrameStack, VecNormalize, VecVideoRecorder\n",
    "from stable_baselines3 import PPO, A2C, TD3\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.base_class import BaseAlgorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.env.observation_wrapper import ImageWrapper\n",
    "from src.callbacks.episodic_callback import EpisodicCallback\n",
    "from src.evaluation import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test(\n",
    "    model: BaseAlgorithm, \n",
    "    model_path: str,\n",
    "    env: gym.Env, \n",
    "    eval_env: gym.Env, \n",
    "    train_steps: int = 50000,  \n",
    "    n_test_episodes: int=10,\n",
    "    **train_kwargs: Optional[dict],\n",
    ") -> Tuple[BaseAlgorithm, float, float]:\n",
    "    \n",
    "    env.reset()\n",
    "    model.learn(train_steps, callback=EpisodicCallback(), **train_kwargs)\n",
    "    model.save(model_path)\n",
    "    mean_reward, std_reward = evaluate(model, eval_env, n_test_episodes)\n",
    "    \n",
    "    env.close()\n",
    "    eval_env.close()\n",
    "    \n",
    "    return mean_reward, std_reward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image processing experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = DummyVecEnv([lambda: gym.make(\"CarRacing-v0\")])\n",
    "eval_env = DummyVecEnv([lambda: gym.make(\"CarRacing-v0\")])\n",
    "model_ppo = PPO('CnnPolicy', env, tensorboard_log='../logs/', verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "mean_reward, std_reward = train_test(model_ppo, \"../models/PPO_base\", env, eval_env, tb_log_name=\"PPO_base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_reward, std_reward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frame stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FRAME_STACK_SIZE = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = DummyVecEnv([lambda: gym.make(\"CarRacing-v0\")])\n",
    "env = VecFrameStack(env, FRAME_STACK_SIZE)\n",
    "\n",
    "eval_env = DummyVecEnv([lambda: gym.make(\"CarRacing-v0\")])\n",
    "eval_env = VecFrameStack(eval_env, FRAME_STACK_SIZE)\n",
    "\n",
    "model_ppo = PPO('CnnPolicy', env, tensorboard_log='../logs/', verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "mean_reward, std_reward = train_test(model_ppo, \"../models/PPO_stack\", env, eval_env, tb_log_name=\"PPO_stack\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_reward, std_reward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = DummyVecEnv([lambda: ImageWrapper(gym.make(\"CarRacing-v0\"), grayscale=False, normalize=True)])\n",
    "eval_env = DummyVecEnv([lambda: ImageWrapper(gym.make(\"CarRacing-v0\"), grayscale=False, normalize=True)])\n",
    "model_ppo = PPO('CnnPolicy', env, tensorboard_log='../logs/', verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "mean_reward, std_reward = train_test(model_ppo, \"../models/PPO_normalized\", env, eval_env, train_steps=100000, tb_log_name=\"PPO_normalized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_reward, std_reward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image processing - grayscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = DummyVecEnv([lambda: ImageWrapper(gym.make(\"CarRacing-v0\"), grayscale=True)])\n",
    "eval_env = DummyVecEnv([lambda: ImageWrapper(gym.make(\"CarRacing-v0\"), grayscale=True)])\n",
    "model_ppo = PPO('CnnPolicy', env, tensorboard_log='../logs/', verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "mean_reward, std_reward = train_test(model_ppo, \"../models/PPO_grayscale\", env, eval_env, train_steps=100000, tb_log_name=\"PPO_grayscale\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_reward, std_reward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reward normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = DummyVecEnv([lambda: ImageWrapper(gym.make(\"CarRacing-v0\"), grayscale=False)])\n",
    "env = VecNormalize(env, norm_obs=False, norm_reward=True)\n",
    "\n",
    "eval_env = DummyVecEnv([lambda: ImageWrapper(gym.make(\"CarRacing-v0\"), grayscale=False)])\n",
    "model_ppo = PPO('CnnPolicy', env, tensorboard_log='../logs/', verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# reset_num_timesteps=False\n",
    "mean_reward, std_reward = train_test(model_ppo, \"../models/PPO_reward_norm\", env, eval_env, train_steps=100000, tb_log_name=\"PPO_reward_norm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_reward, std_reward = evaluate(model_ppo, eval_env, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_reward, std_reward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A2C grayscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = DummyVecEnv([lambda: ImageWrapper(gym.make(\"CarRacing-v0\"), grayscale=True)])\n",
    "eval_env = DummyVecEnv([lambda: ImageWrapper(gym.make(\"CarRacing-v0\"), grayscale=True)])\n",
    "model_a2c = A2C('CnnPolicy', env, tensorboard_log='../logs/', verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "mean_reward, std_reward = train_test(model_a2c, \"../models/A2C_grayscale\", env, eval_env, train_steps=100000, tb_log_name=\"A2C_grayscale\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_reward, std_reward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Summary**: The best result was achived by the use of grayscale image processing. This transformation will be used in next experiments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train longer best model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = DummyVecEnv([lambda: ImageWrapper(gym.make(\"CarRacing-v0\"), grayscale=True)])\n",
    "eval_env = DummyVecEnv([lambda: ImageWrapper(gym.make(\"CarRacing-v0\"), grayscale=True)])\n",
    "\n",
    "model = PPO.load(\"../models/PPO_grayscale\", env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_reward, std_reward = train_test(model, \"../models/PPO_grayscale\", env, eval_env, train_steps=300000, tb_log_name=\"PPO_grayscale\", reset_num_timesteps=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_reward, std_reward = evaluate(model, eval_env, 10)\n",
    "mean_reward, std_reward "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate gameplay video\n",
    "test_env = DummyVecEnv([lambda: ImageWrapper(gym.make(\"CarRacing-v0\"), grayscale=True)])\n",
    "\n",
    "images = []\n",
    "obs = test_env.reset()\n",
    "done = False\n",
    "while not done:\n",
    "    img = test_env.render(mode='rgb_array')\n",
    "    images.append(img)\n",
    "    action = model.predict(obs)\n",
    "    obs, rewards, dones, _ = test_env.step(action[0])\n",
    "    done = dones[0]\n",
    "\n",
    "imageio.mimsave('../resources/gameplay.gif', [np.array(img) for i, img in enumerate(images) if i%2 == 0], fps=29)\n",
    "test_env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gat",
   "language": "python",
   "name": "gat"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
